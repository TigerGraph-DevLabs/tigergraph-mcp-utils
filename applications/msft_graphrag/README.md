# Microsoft's GraphRAG with TigerGraph Integration

[Microsoft's GraphRAG](https://microsoft.github.io/graphrag/) is a method for creating structured knowledge graphs from raw text, enhancing Retrieval Augmented Generation (RAG) tasks. It organizes information hierarchically, enabling more efficient data retrieval and summarization.

This project leverages GraphRAG to transform documents into structured data, which is then imported into TigerGraph using TigerGraphX. The goal is to enable complex queries on the data without relying on the GraphRAG package, providing a seamless integration with TigerGraph's capabilities.


## 1. Indexing

The indexing step prepares your data for GraphRAG processing by setting up the environment, initializing the system, and converting documents into a structured format. Follow these steps to ensure your data is ready for the next stages. For more details, visit [link](https://microsoft.github.io/graphrag/get_started/).

### 1.1 Data Preparation

#### Create an "input" Folder
Create a folder named "input" in your working directory to store the documents you want to index.
```bash
mkdir -p [Your working directory]/input
```

#### Copy Documents to "input" Folder
Place your documents in the "input" folder. For example, ensure `fin.txt` is located in the "input" folder.

### 1.2 Initialization

Initialize the indexing system in the root directory for GraphRAG.
```bash
python3 -m graphrag init --root [Your working directory]
```

### 1.3 Setting Up OpenAI API Key

To use the OpenAI API, set the `GRAPHRAG_API_KEY` environment variable. Edit the `.env` file in your working directory:
```bash
vi [Your working directory]/.env
```
Replace `<API_KEY>` with your actual OpenAI API key.

**Note:** By default, GraphRAG uses the `gpt-4-turbo-preview` model. To save costs, you can switch to the `gpt-4o-mini` model. To modify the model, update the `setting.yaml` file in your working directory as follows:
```yaml
llm:
  api_key: ${GRAPHRAG_API_KEY}
  type: openai_chat # or azure_openai_chat
  # model: gpt-4-turbo-preview
  model: gpt-4o-mini # Updated model to gpt-4o-mini
```

### 1.4 Indexing

Run the indexing process to extract structured data from your document using LLMs. Note: This process may take some time. For example, on a MacBook Pro with an M1 chip, indexing a 242K financial dataset takes approximately 4 minutes.

```bash
python3 -m graphrag index --no-cache --root [Your working directory]
```

## 2. Data Preprocessing

In the data preprocessing step, the structured data generated by GraphRAG is converted into a format that can be easily imported into TigerGraph. This involves transforming Parquet files into CSV files, which are compatible with TigerGraph's data import requirements. Follow these instructions to prepare your data for querying within TigerGraph.

Convert the Parquet files generated by GraphRAG into CSV files compatible with TigerGraph.
```bash
python3 data_import/convert_parquet_to_tg_csv.py \
--input_dir [Your working directory]/output \
--output_dir [Your working directory]/tg_csv
```

Transfer the files to the TigerGraph server. In this demo, place them in the `/home/tigergraph/data/graphrag` directory. You can use the following `scp` command to transfer the files:
```bash
scp [Your working directory]/tg_csv/* username@tigergraph-server:/home/tigergraph/data/graphrag
```

Replace `username` with your actual username on the TigerGraph server and `tigergraph-server` with the server's address or IP.

## 3. Query


