{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f4ca83-4f36-4fc1-947f-b23bfb672f90",
   "metadata": {},
   "source": [
    "# Supporting Simple GraphRAG: Part 2 - Context Retrieval and Answer Generation\n",
    "\n",
    "To run this Jupyter Notebook, you can download the original `.ipynb` file from [simple_graphrag_2.ipynb](https://github.com/tigergraph/tigergraphx/tree/main/docs/graphrag/simple_graphrag_2.ipynb).\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "The query process of GraphRAG follows this workflow. TigerGraphX serves as the key interface, facilitating interaction with the embedding model to generate embeddings for user queries, retrieving context from TigerGraph, and communicating with the LLM chat model to generate answers.\n",
    "\n",
    "![](https://github.com/tigergraph/tigergraphx/blob/main/docs/images/graphrag/querying.png?raw=true)\n",
    "\n",
    "---\n",
    "\n",
    "## Get the Graph from TigerGraph\n",
    "Since the graph has already been created in TigerGraph, redefining its schema is unnecessary. Instead, you can provide the graph name to retrieve it. TigerGraphX will verify if the graph exists in TigerGraph and, if it does, will return the corresponding graph.\n",
    "\n",
    "### Define the TigerGraph Connection Configuration\n",
    "Before retrive the graph schema from TigerGraph, you shoulddefine the  TigerGraph Connection Configuration first.\n",
    "The recommended approach is to use environment variables, such as setting them with the `export` command in the shell. Here, to illustrate the demo, we configure them within Python using the `os.environ` method. You can find more methods for configuring connection settings in [Graph.\\_\\_init\\_\\_](../reference/01_core/graph.md#tigergraphx.core.graph.Graph.__init__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e123f27-c2aa-47a4-8293-34960ade8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import os\n",
    ">>> os.environ[\"TG_HOST\"] = \"http://127.0.0.1\"\n",
    ">>> os.environ[\"TG_USERNAME\"] = \"tigergraph\"\n",
    ">>> os.environ[\"TG_PASSWORD\"] = \"tigergraph\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30ed07-e331-4796-bca0-26975dbc3010",
   "metadata": {},
   "source": [
    "### Retrieve the Graph\n",
    "Once a graph has been created in TigerGraph, you can retrieve it without manually defining the schema using the `Graph.from_db` method, which requires only the graph name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff16e1ca-52e2-478a-844f-d478b5cc7659",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from tigergraphx import Graph\n",
    ">>> G = Graph.from_db(\"RetailGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6465ab-8b34-40b4-a87e-f85a9f0b2c17",
   "metadata": {},
   "source": [
    "---\n",
    "## Context Building: Writing Custom Context Builders\n",
    "\n",
    "Context builders play a vital role in graph-powered RAG workflows. They transform retrieved graph data into structured, meaningful contexts for tasks such as interactions with LLMs.\n",
    "\n",
    "TigerGraphX simplifies this process by offering the flexible `BaseContextBuilder` class, which allows developers to define custom logic for context building. You can find the source code in [this link](https://github.com/TigerGraph-DevLabs/tigergraphx/blob/main/tigergraphx/graphrag/base_context_builder.py).\n",
    "\n",
    "In this example, we create a simple `ContextBuilder` by implementing the `build_context` method to define how the context is constructed. The process involves:  \n",
    "\n",
    "- Retrieving the top **k** relevant objects (products) using TigerGraph's vector search.  \n",
    "- For each retrieved product, fetching its properties and edges.  \n",
    "- Concatenating all the gathered information into a structured context and returning it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113c01f3-1245-4ee8-b575-0c2977a0c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:15:41,490 - datasets - INFO - PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    ">>> from typing import List\n",
    ">>> from tigergraphx.graphrag import BaseContextBuilder\n",
    "\n",
    ">>> class ContextBuilder(BaseContextBuilder):\n",
    "...     async def build_context(self, query: str, k: int = 10) -> str | List[str]:\n",
    "...         \"\"\"Build local context.\"\"\"\n",
    "...         context: List[str] = []\n",
    "... \n",
    "...         # Retrieve top-k objects\n",
    "...         top_k_objects: List[str] = await self.retrieve_top_k_objects(\n",
    "...             query, k=k, oversample_scaler=1\n",
    "...         )\n",
    "...         if not top_k_objects:\n",
    "...             return \"\"  # Return early if no objects are retrieved\n",
    "... \n",
    "...         # Iterate over all products\n",
    "...         for product in top_k_objects:\n",
    "...             node_data = self.graph.get_node_data(product, \"Product\")\n",
    "...             edges = self.graph.get_node_edges(product, \"Product\")\n",
    "...             context.append(f\"Node Data for {product}: {node_data}\")\n",
    "...             context.append(f\"Edges for {product}: {edges}\")\n",
    "... \n",
    "...         return \"\\n\\n\".join(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0f346-6909-4865-aa52-9942e2d30dc2",
   "metadata": {},
   "source": [
    "Hereâ€™s how you can utilize the custom context builder to integrate it with TigerGraphX and OpenAI components:  \n",
    "\n",
    "- **Configure Vector Search:** The `vector_db` settings specify that the search engine will use **TigerVector** to retrieve relevant **Product** nodes based on their `emb_features` attribute.  \n",
    "- **Set Up OpenAI Components:** The configuration defines models for **LLM**, **embedding**, and **chat**, ensuring that API keys are securely managed via environment variables.  \n",
    "- **Initialize OpenAI and Search Engine:** The `create_openai_components` function instantiates the OpenAI chat model and the vector-based search engine for retrieving relevant nodes.  \n",
    "- **Create Context Builder:** The `ContextBuilder` is initialized with the graph and search engine, allowing it to retrieve and structure context dynamically for downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e975ef-4ff0-446a-937a-4c40acf87395",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from tigergraphx.factories import create_openai_components\n",
    ">>> settings = {\n",
    "...     \"vector_db\": {\n",
    "...         \"type\": \"TigerVector\",\n",
    "...         \"graph_name\": \"RetailGraph\",\n",
    "...         \"node_type\": \"Product\",\n",
    "...         \"vector_attribute_name\": \"emb_features\",\n",
    "...     },\n",
    "...     \"llm\": {\n",
    "...         \"type\": \"OpenAI\",\n",
    "...         # NOTE: The api_key must be provided via the environment variable OPENAI_API_KEY\n",
    "...     },\n",
    "...     \"embedding\": {\n",
    "...         \"type\": \"OpenAI\",\n",
    "...         \"model\": \"text-embedding-3-small\",\n",
    "...     },\n",
    "...     \"chat\": {\n",
    "...         \"type\": \"OpenAI\",\n",
    "...         \"model\": \"gpt-4o-mini\",\n",
    "...     },\n",
    "... }\n",
    ">>> (openai_chat, search_engine) = create_openai_components(settings, G)\n",
    ">>> context_builder = ContextBuilder(graph=G, search_engine=search_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627fef8-4099-4356-8eba-b399cda15005",
   "metadata": {},
   "source": [
    "Let's verify that the context builder functions as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3312bae2-6947-4279-ac6a-da77b3263fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:15:46,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Node Data for SnapShot Voyager Remote Shutter Release: {'name': 'SnapShot Voyager Remote Shutter Release', 'price': 24.99, 'weight': 40, 'features': \"Reduced Camera Shake: Allows you to trigger the shutter without touching the camera, minimizing movement and ensuring sharper images. Convenient Control: Provides a comfortable and ergonomic grip with a simple button to activate the shutter. Long Cable: Offers flexibility and ease of use with a generous cable length. Easy Connection: Plugs directly into the camera's remote port for quick and simple setup.\"}\n",
      "\n",
      "Edges for SnapShot Voyager Remote Shutter Release: [('SnapShot Voyager Camera 3.0', 'SnapShot Voyager Remote Shutter Release'), ('SnapShot Voyager Remote Shutter Release', 'SnapShot Voyager Camera 3.0'), ('SnapShot Voyager Remote Shutter Release', 'Photography')]\n",
      "\n",
      "Node Data for Aura X5 Pro: {'name': 'Aura X5 Pro', 'price': 1299, 'weight': 205, 'features': 'Advanced Camera System: Featuring a 50MP primary sensor with OIS, a 12MP ultrawide lens, and a 10MP telephoto lens with 3x optical zoom, the Aura X5 Pro captures professional-quality images in any lighting conditions. Extended Battery Life: The 5000mAh battery delivers all-day power, allowing you to browse, stream, and create without worrying about running out of charge. Supports 65W fast charging. Brilliant Display: Immerse yourself in vibrant colors and sharp details on the 6.7-inch AMOLED display with a 120Hz refresh rate. Powerful Performance: Powered by the Snapdragon 8 Gen 2 processor, the Aura X5 Pro delivers lightning-fast performance for gaming, multitasking, and demanding applications. Enhanced Security: Features an in-display fingerprint sensor and advanced facial recognition for secure and convenient unlocking. Durable Design: Crafted with a premium aluminum frame and Gorilla Glass Victus+ on both the front and back for exceptional durability.'}\n",
      "\n",
      "Edges for Aura X5 Pro: [('Aura X5', 'Aura X5 Pro'), ('Aura X5 Pro', 'Phone'), ('Aura X5 Pro', 'Mobile Phones'), ('Aura X5 Pro', 'Aura X5'), ('Aura X5 Pro', 'Home')]\n",
      "\n",
      "Node Data for SnapShot Voyager Camera 3.0: {'name': 'SnapShot Voyager Camera 3.0', 'price': 249.99, 'weight': 350, 'features': 'Intuitive Interface: Navigate settings and modes effortlessly with a user-friendly touchscreen and simple controls. High-Resolution Sensor: Capture sharp, vibrant photos and videos with a 24-megapixel sensor. Optical Image Stabilization: Reduce blur from camera shake for clear images even in low light or while in motion. 4K Video Recording: Record smooth, high-definition video at 4K resolution. Built-in Wi-Fi: Easily transfer photos and videos to your smartphone or tablet for sharing. Versatile Shooting Modes: Choose from a variety of modes, including portrait, landscape, sports, and night mode. Long Battery Life: Enjoy extended shooting sessions with a long-lasting rechargeable battery.'}\n",
      "\n",
      "Edges for SnapShot Voyager Camera 3.0: [('SnapShot Voyager Lens Hood', 'SnapShot Voyager Camera 3.0'), ('SnapShot Voyager Remote Shutter Release', 'SnapShot Voyager Camera 3.0'), ('SnapShot Voyager Camera 3.0', 'Camera'), ('SnapShot Voyager Camera 3.0', 'Home'), ('SnapShot Voyager Camera 3.0', 'SnapShot Voyager Remote Shutter Release'), ('SnapShot Voyager Camera 3.0', 'SnapShot Voyager Lens Hood'), ('SnapShot Voyager Camera 3.0', 'Photography')]\n",
      "\n",
      "Node Data for AuraBook Air: {'name': 'AuraBook Air', 'price': 999, 'weight': 2.5, 'features': 'Ultra-lightweight design for maximum portability. Brilliant 13.3-inch Full HD Display. Fast and responsive performance. Long-lasting battery life for all-day use. Integrated HD webcam for video conferencing. Sleek, modern design.'}\n",
      "\n",
      "Edges for AuraBook Air: [('AuraBook Air', 'Computer'), ('AuraBook Air', 'Office'), ('AuraBook Air', 'Laptops'), ('AuraBook Air', 'Home')]\n",
      "\n",
      "Node Data for SkyHawk Zephyr Drone: {'name': 'SkyHawk Zephyr Drone', 'price': 0, 'weight': 0, 'features': 'Simple Controls: Beginner friendly and intuitive controls, plus automatic takeoff and landing. Tough Build: Designed to handle rookie mistakes, thanks to its robust construction. Capture Memories: Record crisp HD photos and videos from above. Extended Fun: Enjoy up to 15 minutes of flight time per charge. Worry-Free Flying: Free Fly mode lets you fly without directional concerns.'}\n",
      "\n",
      "Edges for SkyHawk Zephyr Drone: [('SkyHawk Zephyr 2.0 - Reach New Heights', 'SkyHawk Zephyr Drone'), ('SkyHawk Zephyr Drone', 'Videography'), ('SkyHawk Zephyr Drone', 'SkyHawk Zephyr Propeller Guards'), ('SkyHawk Zephyr Drone', 'Drone'), ('SkyHawk Zephyr Propeller Guards', 'SkyHawk Zephyr Drone'), ('SkyHawk Zephyr Extended Battery', 'SkyHawk Zephyr Drone'), ('SkyHawk Zephyr Drone', 'SkyHawk Zephyr Extended Battery'), ('SkyHawk Zephyr Drone', 'Home'), ('SkyHawk Zephyr Drone', 'SkyHawk Zephyr 2.0 - Reach New Heights'), ('SkyHawk Zephyr Drone', 'Photography')]\n",
      "\n",
      "Node Data for SkyHawk Zephyr Extended Battery: {'name': 'SkyHawk Zephyr Extended Battery', 'price': 29.99, 'weight': 70, 'features': 'Increased Capacity: Enjoy up to 25 minutes of flight time on a single charge, a 67% increase over the standard battery. Easy Installation: Seamlessly swap out with the original battery in seconds. Safe and Reliable: Built to the same high-quality standards as the SkyHawk Zephyr drone.'}\n",
      "\n",
      "Edges for SkyHawk Zephyr Extended Battery: [('SkyHawk Zephyr Drone', 'SkyHawk Zephyr Extended Battery'), ('SkyHawk Zephyr Extended Battery', 'Videography'), ('SkyHawk Zephyr Extended Battery', 'Photography'), ('SkyHawk Zephyr Extended Battery', 'SkyHawk Zephyr Drone')]\n",
      "\n",
      "Node Data for SkyHawk Zephyr 2.0 - Reach New Heights: {'name': 'SkyHawk Zephyr 2.0 - Reach New Heights', 'price': 199.99, 'weight': 250, 'features': '4K Camera: Capture breathtaking aerial footage in stunning 4K resolution with enhanced image stabilization. Extended Flight Time: Enjoy up to 20 minutes of flight time on a single charge. Increased Range: Fly farther with an extended control range of up to 1.2km (3/4 mile). Intelligent Flight Modes: Explore creative filming options with Follow Me, Orbit, and Waypoint modes. GPS-Assisted Flight: Benefit from precise positioning and enhanced safety features like Return-to-Home. Upgraded Motors: Experience smoother, more responsive flight and increased agility. Streamlined Design: A sleek and aerodynamic design for improved flight performance.'}\n",
      "\n",
      "Edges for SkyHawk Zephyr 2.0 - Reach New Heights: [('SkyHawk Zephyr Drone', 'SkyHawk Zephyr 2.0 - Reach New Heights'), ('SkyHawk Zephyr 2.0 - Reach New Heights', 'Drone'), ('SkyHawk Zephyr 2.0 - Reach New Heights', 'Photography'), ('SkyHawk Zephyr 2.0 - Reach New Heights', 'SkyHawk Zephyr Drone'), ('SkyHawk Zephyr 2.0 - Reach New Heights', 'Home'), ('SkyHawk Zephyr 2.0 - Reach New Heights', 'Videography')]\n",
      "\n",
      "Node Data for  answer questions: {'name': ' answer questions', 'price': 0, 'weight': 0, 'features': ''}\n",
      "\n",
      "Edges for  answer questions: []\n",
      "\n",
      "Node Data for SkyHawk Zephyr Propeller Guards: {'name': 'SkyHawk Zephyr Propeller Guards', 'price': 14.99, 'weight': 20, 'features': 'Enhanced Safety: Prevent accidental damage to the propellers and surroundings during flight. Lightweight Design: Minimal impact on flight performance. Easy Installation: Snap on and off in seconds for quick and convenient use. Increased Durability: Provides an extra layer of protection for your drone.'}\n",
      "\n",
      "Edges for SkyHawk Zephyr Propeller Guards: [('SkyHawk Zephyr Drone', 'SkyHawk Zephyr Propeller Guards'), ('SkyHawk Zephyr Propeller Guards', 'Photography'), ('SkyHawk Zephyr Propeller Guards', 'SkyHawk Zephyr Drone'), ('SkyHawk Zephyr Propeller Guards', 'Videography')]\n",
      "\n",
      "Node Data for ChromaJet Starter Bundle: {'name': 'ChromaJet Starter Bundle', 'price': 528, 'weight': 12, 'features': 'Complete Starter Package: Includes printer and cleaning kit for immediate use. Professional-Grade Quality: Produce high-resolution prints with exceptional color accuracy. User-Friendly Interface: Intuitive controls for easy operation, even for beginners. Versatile Media Handling: Supports a wide range of paper types and sizes. Durable Construction: Built to last, ensuring years of reliable performance.'}\n",
      "\n",
      "Edges for ChromaJet Starter Bundle: [('ChromaJet Starter Bundle', 'Printing')]\n"
     ]
    }
   ],
   "source": [
    ">>> context = await context_builder.build_context(\"I am looking for a begginer drone. Please give me some recommendations.\")\n",
    ">>> print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6301c-6a75-4e55-abd2-edc423636c16",
   "metadata": {},
   "source": [
    "Congratulations! It works.  \n",
    "\n",
    "---  \n",
    "\n",
    "## Generate Answer  \n",
    "\n",
    "The final step is to generate an answer using the LLM.  \n",
    "\n",
    "### Define a Prompt  \n",
    "First, let's define a prompt template for the LLM to generate an answer as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82cf696f-9649-4f2f-a039-87cbe22b5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> PROMPTS = \"\"\"---Role---\n",
    "... \n",
    "... You are a helpful assistant responding to questions about data in the tables provided.\n",
    "... \n",
    "... \n",
    "... ---Goal---\n",
    "... \n",
    "... Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
    "... If you don't know the answer, just say so. Do not make anything up.\n",
    "... Do not include information where the supporting evidence for it is not provided.\n",
    "... \n",
    "... ---Target response length and format---\n",
    "... \n",
    "... {response_type}\n",
    "... \n",
    "... \n",
    "... ---Data tables---\n",
    "... \n",
    "... {context_data}\n",
    "... \n",
    "... \n",
    "... ---Goal---\n",
    "... \n",
    "... Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
    "... \n",
    "... If you don't know the answer, just say so. Do not make anything up.\n",
    "... \n",
    "... Do not include information where the supporting evidence for it is not provided.\n",
    "... \n",
    "... \n",
    "... ---Target response length and format---\n",
    "... \n",
    "... {response_type}\n",
    "... \n",
    "... Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40cab2-cc1e-4ab0-bfa1-921076263fb9",
   "metadata": {},
   "source": [
    "### Define a Function to Generate Answer\n",
    "\n",
    "Then let's define a `query` function that integrates the context builder and OpenAIChat to process user queries. This function retrieves relevant context from the graph, constructs a system prompt, and generates a response using the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52da85ea-6288-4c4b-bfac-7a3d2b9168cd",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from tigergraphx.graphrag import BaseContextBuilder\n",
    ">>> from tigergraphx.llm import OpenAIChat\n",
    ">>> async def query(\n",
    "...     query: str,\n",
    "...     openai_chat: OpenAIChat,\n",
    "...     context_builder: BaseContextBuilder,\n",
    "...     top_k: int = 10,\n",
    "...     only_need_context: bool = False,\n",
    "...     response_type: str = \"Multiple Paragraphs\",\n",
    "... ) -> str:\n",
    "...     \"\"\"\n",
    "...     Perform a local search using the context builder and return the result.\n",
    "...     \"\"\"\n",
    "...     # Generate context using the local context builder\n",
    "...     context = await context_builder.build_context(\n",
    "...         query,\n",
    "...         k=top_k,\n",
    "...     )\n",
    "...     if only_need_context:\n",
    "...         if not isinstance(context, str):\n",
    "...             raise TypeError(\"Expected `context` to be an instance of str.\")\n",
    "...         return context\n",
    "... \n",
    "...     # Validate that context exists\n",
    "...     if not context:\n",
    "...         return \"Apologies, but I couldn't provide an answer as no relevant context was found for your query.\"\n",
    "... \n",
    "...     # Construct the system prompt using the context\n",
    "...     system_prompt = PROMPTS.format(context_data=context, response_type=response_type)\n",
    "... \n",
    "...     # Perform the query using OpenAIChat\n",
    "...     try:\n",
    "...         response = await openai_chat.chat(\n",
    "...             [\n",
    "...                 {\"role\": \"system\", \"content\": system_prompt},\n",
    "...                 {\"role\": \"user\", \"content\": query},\n",
    "...             ]\n",
    "...         )\n",
    "...         return response\n",
    "...     except Exception:\n",
    "...         return \"An error occurred while processing the query.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a2b72-7538-4ea3-93a5-16eafc7eb1de",
   "metadata": {},
   "source": [
    "### Run the Function to Generate an Answer  \n",
    "Great job! The final step is to provide a question and call the function to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae88bcc-666c-4445-8426-4649dab80ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:15:53,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-28 15:16:04,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "### Recommendations for Beginner Drones\n",
      "\n",
      "When it comes to selecting a beginner-friendly drone, it's essential to consider ease of use, durability, and features that enhance the flying experience. Based on available data, here are two excellent options for beginner drones:\n",
      "\n",
      "#### 1. SkyHawk Zephyr Drone\n",
      "\n",
      "**Price:** $0 (likely indicating it comes free with a package or promotional offer)\n",
      "\n",
      "**Features:**\n",
      "- **Simple Controls:** This drone is designed with beginner-friendly and intuitive controls, plus it includes automatic takeoff and landing capabilities to ease new users into flying.\n",
      "- **Robust Build:** The SkyHawk Zephyr is constructed to withstand typical beginner mistakes, making it durable and reliable for novice pilots.\n",
      "- **Photography and Videography:** Equipped with an HD camera, it allows users to capture crisp photos and videos from above, appealing to those interested in aerial photography.\n",
      "- **Flight Time:** Users can enjoy approximately 15 minutes of flight time per charge, giving a decent amount of flying enjoyment.\n",
      "\n",
      "Given its features, the SkyHawk Zephyr Drone is a fantastic option for newcomers to the world of drones, providing an intuitive flying experience while delivering quality content during flights.\n",
      "\n",
      "#### 2. SkyHawk Zephyr 2.0 - Reach New Heights\n",
      "\n",
      "**Price:** $199.99\n",
      "\n",
      "**Features:**\n",
      "- **4K Camera:** This drone boasts a high-quality 4K camera, perfect for capturing stunning aerial footage, appealing to users looking to create high-definition content.\n",
      "- **Extended Flight Time:** With up to 20 minutes of flight time on a single charge, users can enjoy longer flying sessions.\n",
      "- **Intelligent Flight Modes:** It offers advanced flight options such as Follow Me, Orbit, and Waypoint modes for creative filming, making it great for users interested in exploring versatile filming capabilities.\n",
      "- **GPS-Assisted Flight:** Features like Return-to-Home enhance safety for beginners, ensuring that even those new to flying can have a worry-free experience.\n",
      "\n",
      "The SkyHawk Zephyr 2.0 presents a step up in features from the base model. It's suitable for beginners who want to grow their skills while still having access to advanced features for creative pursuits.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Both the SkyHawk Zephyr Drone and the SkyHawk Zephyr 2.0 are excellent choices for beginner drone enthusiasts. The former is particularly good for pure novices due to its straightforward controls and robust build, while the latter provides additional features that enhance the flying experience as users become more comfortable. When selecting a drone, consider your specific needs, such as the desire for photography or content creation, and choose the model that aligns best with those interests.\n"
     ]
    }
   ],
   "source": [
    ">>> result = await query(\n",
    "...     query=\"I am looking for a begginer drone. Please give me some recommendations.\",\n",
    "...     openai_chat=openai_chat,\n",
    "...     context_builder=context_builder,\n",
    "...     only_need_context=False,\n",
    "... )\n",
    ">>> print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa73ea-7b53-4776-a79a-8031c7ba4fc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reset\n",
    "\n",
    "After completing the query, it is recommended to clean up the environment by removing the graph you created. You can drop the graph by running the following single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea58c6b-3a22-47a7-b75a-2c4c06fbc9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:20:17,365 - tigergraphx.core.managers.schema_manager - INFO - Dropping graph: RetailGraph...\n",
      "2025-03-28 15:20:22,112 - tigergraphx.core.managers.schema_manager - INFO - Graph dropped successfully.\n"
     ]
    }
   ],
   "source": [
    ">>> G.drop_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922d3d6-6dcd-40f8-87b5-eb8a2c65eef3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Whatâ€™s Next?\n",
    "\n",
    "- [API Reference](../reference/introduction.md): Dive deeper into TigerGraphX APIs.\n",
    "\n",
    "---\n",
    "\n",
    "Start transforming your GraphRAG workflows with the power of **TigerGraphX** today!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
